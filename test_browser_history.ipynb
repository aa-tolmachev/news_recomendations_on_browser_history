{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file:///C:/Users/Admin/AppData/Local/Google/Chrome/User%20Data/Default/\n",
    "# go to this link in browser if want to check internal info of google browser\n",
    "\n",
    "#http://bar-navig.yandex.ru/u?show=31&url=https://www.coursera.org\n",
    "#on this lick we get xml response about web_site\n",
    "\n",
    "#https://www.kakprosto.ru/kak-109671-kak-uznat-tematiku-sayta\n",
    "#on this lick we can get insructions to parse site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir already here \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "data_path = os.path.expanduser('~')+\"\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Default\"\n",
    "\n",
    "srcfile = data_path+'\\\\History'\n",
    "\n",
    "try:\n",
    "    dstroot = 'chrome_history'\n",
    "    dstdir =  os.path.join(dstroot)\n",
    "    os.makedirs(dstdir) \n",
    "except:\n",
    "    print ('dir already here ')\n",
    "\n",
    "\n",
    "shutil.copy(srcfile, dstdir)\n",
    "\n",
    "data_path = dstdir+'\\\\History'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT v.id , v.url as url_id , v.visit_time , v.visit_duration \n",
      " , datetime(v.visit_time/1000000-11644473600,'unixepoch','localtime') as dt_visit_time \n",
      " , u.url , u.title , u.visit_count , u.typed_count ,  \n",
      "datetime(u.last_visit_time/1000000-11644473600,'unixepoch','localtime') as dt_last_visit \n",
      "from visits v \n",
      "left join urls u on v.url = u.id   \n",
      "order by  2 desc\n"
     ]
    }
   ],
   "source": [
    "select_statement = \"SELECT * FROM urls, visits WHERE urls.id = visits.url;\"\n",
    "select_statement = \"select datetime(last_visit_time/1000000-11644473600,'unixepoch','localtime') as dt_last_visit, * FROM urls ORDER BY last_visit_time DESC\"\n",
    "\n",
    "select_statement = ''.join([\n",
    "                        'SELECT ' , 'v.id , v.url as url_id , v.visit_time , v.visit_duration', ' \\n'\n",
    "                                  ,\" , datetime(v.visit_time/1000000-11644473600,'unixepoch','localtime') as dt_visit_time\" , ' \\n'\n",
    "                                  , ' , u.url , u.title , u.visit_count , u.typed_count , ' , ' \\n'\n",
    "                                  , \"datetime(u.last_visit_time/1000000-11644473600,'unixepoch','localtime') as dt_last_visit\" , ' \\n'\n",
    "                        ,'from ' , 'visits v' , ' \\n'\n",
    "                        ,'left join ' , 'urls u on v.url = u.id  ' , ' \\n'\n",
    "                        ,'order by ' , ' 2 desc'\n",
    "                                        \n",
    "                        ])\n",
    "\n",
    "\n",
    "\n",
    "print(select_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = sqlite3.connect(data_path)\n",
    "cursor = c.cursor()\n",
    "\n",
    "\n",
    "\n",
    "cursor.execute(select_statement)\n",
    "\n",
    "\n",
    "df_chrome_history = pd.read_sql_query(select_statement, c)\n",
    "\n",
    "df_chrome_history['dt_last_visit'] =  [ datetime.strptime( x , '%Y-%m-%d %H:%M:%S') for x in df_chrome_history['dt_last_visit'] ]\n",
    "df_chrome_history['dt_visit_time'] =  [ datetime.strptime( x , '%Y-%m-%d %H:%M:%S') for x in df_chrome_history['dt_visit_time'] ]\n",
    "df_chrome_history.drop(['visit_time'], axis=1 , inplace = True)\n",
    "\n",
    "#очистим данные от мусора\n",
    "documents = [re.split('/', x)[2] for x in  df_chrome_history['url']]\n",
    "df_chrome_history['documents'] = documents\n",
    "c.close()\n",
    "\n",
    "#очистим от мусорных сайтов\n",
    "trash = ['mail.google.com' , 'docs.google.com' , 'e.mail.ru' , 'gmail.com' , 'mail.ru']\n",
    "\n",
    "df_chrome_history = df_chrome_history[(df_chrome_history.documents != 'localhost:8888')\n",
    "                                     &(df_chrome_history.title != '')\n",
    "                                     &~(df_chrome_history.documents.isin(trash))\n",
    "                                     ][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documents</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>www.youtube.com</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.google.ru</th>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.coursera.org</th>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive.google.com</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github.com</th>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.avito.ru</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vk.com</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru.aliexpress.com</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basecamp.com</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.drive2.ru</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflow.com</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pikabu.ru</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24paybank.com</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lkfl.nalog.ru</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.google.com</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtube.com</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sufraperm.ru</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radio.yandex.ru</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade.aliexpress.com</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>login.aliexpress.com</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.aliexpress.com</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esia.gosuslugi.ru</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>console.developers.google.com</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online.uralfd.ru</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.instagram.com</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evrl.to</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habrahabr.ru</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data.heroku.com</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track.aliexpress.com</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.tinkoff.ru</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp.userapi.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rutracker-net.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pypi.python.org</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru.wikihow.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru.coursera.org</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariadb.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade.alibaba.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mall.aliexpress.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wwhois.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdbscan.readthedocs.io</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdl.handle.net</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru.bmstu.wiki</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.aup.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.astrobetter.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ihakimov.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.afisha.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.8bitx.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intellij-support.jetbrains.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lk.gosuslugi.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winestyle.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows.microsoft.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki.python.org</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itscreen.tk</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kassy.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vestnik.sibsutis.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v-resheno.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linkfeedator.ru</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utorrent.com</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z.umn.edu</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id\n",
       "documents                          \n",
       "www.youtube.com                 337\n",
       "www.google.ru                   287\n",
       "www.coursera.org                267\n",
       "drive.google.com                239\n",
       "github.com                      223\n",
       "www.avito.ru                    169\n",
       "vk.com                          125\n",
       "ru.aliexpress.com               125\n",
       "basecamp.com                    107\n",
       "www.drive2.ru                    78\n",
       "stackoverflow.com                61\n",
       "pikabu.ru                        60\n",
       "24paybank.com                    60\n",
       "lkfl.nalog.ru                    56\n",
       "www.google.com                   55\n",
       "youtube.com                      54\n",
       "sufraperm.ru                     52\n",
       "radio.yandex.ru                  50\n",
       "trade.aliexpress.com             47\n",
       "login.aliexpress.com             40\n",
       "www.aliexpress.com               37\n",
       "esia.gosuslugi.ru                34\n",
       "console.developers.google.com    30\n",
       "online.uralfd.ru                 28\n",
       "www.instagram.com                27\n",
       "evrl.to                          24\n",
       "habrahabr.ru                     23\n",
       "data.heroku.com                  19\n",
       "track.aliexpress.com             19\n",
       "www.tinkoff.ru                   18\n",
       "...                             ...\n",
       "pp.userapi.com                    1\n",
       "rutracker-net.ru                  1\n",
       "pypi.python.org                   1\n",
       "ru.wikihow.com                    1\n",
       "ru.coursera.org                   1\n",
       "mariadb.com                       1\n",
       "trade.alibaba.com                 1\n",
       "mall.aliexpress.com               1\n",
       "wwhois.ru                         1\n",
       "hdbscan.readthedocs.io            1\n",
       "hdl.handle.net                    1\n",
       "ru.bmstu.wiki                     1\n",
       "www.aup.ru                        1\n",
       "www.astrobetter.com               1\n",
       "ihakimov.ru                       1\n",
       "www.afisha.ru                     1\n",
       "www.8bitx.com                     1\n",
       "instagram.com                     1\n",
       "intellij-support.jetbrains.com    1\n",
       "lk.gosuslugi.ru                   1\n",
       "winestyle.ru                      1\n",
       "windows.microsoft.com             1\n",
       "wiki.python.org                   1\n",
       "itscreen.tk                       1\n",
       "kassy.ru                          1\n",
       "vestnik.sibsutis.ru               1\n",
       "v-resheno.ru                      1\n",
       "linkfeedator.ru                   1\n",
       "utorrent.com                      1\n",
       "z.umn.edu                         1\n",
       "\n",
       "[230 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим топ сайтов за последнее время\n",
    "df_chrome_history[(df_chrome_history.dt_last_visit > datetime.now() - timedelta(days=30))].groupby(['documents'])[['id']].count().sort_values('id' , ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#если хотим посмотреть что-то определенное\n",
    "interest = []\n",
    "for i in df_chrome_history['documents'].unique():\n",
    "    if 'github' in i:\n",
    "        interest.append(i)\n",
    "        \n",
    "        \n",
    "df_chrome_history = df_chrome_history[(df_chrome_history.documents.isin(interest))\n",
    "                                      &(df_chrome_history.dt_last_visit > datetime.now() - timedelta(days=8))\n",
    "                                     ][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_id</th>\n",
       "      <th>visit_duration</th>\n",
       "      <th>dt_visit_time</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>visit_count</th>\n",
       "      <th>typed_count</th>\n",
       "      <th>dt_last_visit</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>50036</td>\n",
       "      <td>21842</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 02:20:08</td>\n",
       "      <td>https://github.com/scikit-learn/scikit-learn/b...</td>\n",
       "      <td>scikit-learn/dbscan_.py at master · scikit-lea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 02:20:08</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>49958</td>\n",
       "      <td>21816</td>\n",
       "      <td>482131771</td>\n",
       "      <td>2018-03-30 01:23:18</td>\n",
       "      <td>https://github.com/mwaskom/seaborn/issues/1092</td>\n",
       "      <td>one kdeplot function error of seaborn · Issue ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:18</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>49956</td>\n",
       "      <td>21816</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:15</td>\n",
       "      <td>https://github.com/mwaskom/seaborn/issues/1092</td>\n",
       "      <td>one kdeplot function error of seaborn · Issue ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:18</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>49957</td>\n",
       "      <td>21815</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:17</td>\n",
       "      <td>https://github.com/mwaskom/seaborn/issues/1103</td>\n",
       "      <td>one kdeplot function error of seaborn · Issue ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:17</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>49955</td>\n",
       "      <td>21815</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:15</td>\n",
       "      <td>https://github.com/mwaskom/seaborn/issues/1103</td>\n",
       "      <td>one kdeplot function error of seaborn · Issue ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:17</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>49954</td>\n",
       "      <td>21815</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:06</td>\n",
       "      <td>https://github.com/mwaskom/seaborn/issues/1103</td>\n",
       "      <td>one kdeplot function error of seaborn · Issue ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:23:17</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>49948</td>\n",
       "      <td>21810</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>https://gist.github.com/auth/github/callback?r...</td>\n",
       "      <td>How to plot nice 2d density plots of samples i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>gist.github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>49947</td>\n",
       "      <td>21809</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>https://github.com/login/oauth/authorize?clien...</td>\n",
       "      <td>How to plot nice 2d density plots of samples i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>49946</td>\n",
       "      <td>21808</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>https://gist.github.com/auth/github?return_to=...</td>\n",
       "      <td>How to plot nice 2d density plots of samples i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>gist.github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>49949</td>\n",
       "      <td>21807</td>\n",
       "      <td>8241217</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>https://gist.github.com/dfm/2008724</td>\n",
       "      <td>How to plot nice 2d density plots of samples i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>gist.github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>49945</td>\n",
       "      <td>21807</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>https://gist.github.com/dfm/2008724</td>\n",
       "      <td>How to plot nice 2d density plots of samples i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>gist.github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>49944</td>\n",
       "      <td>21806</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>https://gist.github.com/2008724</td>\n",
       "      <td>How to plot nice 2d density plots of samples i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 01:19:03</td>\n",
       "      <td>gist.github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>49596</td>\n",
       "      <td>21583</td>\n",
       "      <td>23674511</td>\n",
       "      <td>2018-03-28 02:03:22</td>\n",
       "      <td>https://github.com/jazzband/django-pipeline/is...</td>\n",
       "      <td>UnicodeDecodeError: 'utf-8' codec can't decode...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-28 02:03:22</td>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  url_id  visit_duration       dt_visit_time  \\\n",
       "188  50036   21842               0 2018-03-30 02:20:08   \n",
       "214  49958   21816       482131771 2018-03-30 01:23:18   \n",
       "215  49956   21816               0 2018-03-30 01:23:15   \n",
       "216  49957   21815               0 2018-03-30 01:23:17   \n",
       "217  49955   21815               0 2018-03-30 01:23:15   \n",
       "218  49954   21815               0 2018-03-30 01:23:06   \n",
       "223  49948   21810               0 2018-03-30 01:19:03   \n",
       "224  49947   21809               0 2018-03-30 01:19:03   \n",
       "225  49946   21808               0 2018-03-30 01:19:03   \n",
       "226  49949   21807         8241217 2018-03-30 01:19:03   \n",
       "227  49945   21807               0 2018-03-30 01:19:03   \n",
       "228  49944   21806               0 2018-03-30 01:19:03   \n",
       "521  49596   21583        23674511 2018-03-28 02:03:22   \n",
       "\n",
       "                                                   url  \\\n",
       "188  https://github.com/scikit-learn/scikit-learn/b...   \n",
       "214     https://github.com/mwaskom/seaborn/issues/1092   \n",
       "215     https://github.com/mwaskom/seaborn/issues/1092   \n",
       "216     https://github.com/mwaskom/seaborn/issues/1103   \n",
       "217     https://github.com/mwaskom/seaborn/issues/1103   \n",
       "218     https://github.com/mwaskom/seaborn/issues/1103   \n",
       "223  https://gist.github.com/auth/github/callback?r...   \n",
       "224  https://github.com/login/oauth/authorize?clien...   \n",
       "225  https://gist.github.com/auth/github?return_to=...   \n",
       "226                https://gist.github.com/dfm/2008724   \n",
       "227                https://gist.github.com/dfm/2008724   \n",
       "228                    https://gist.github.com/2008724   \n",
       "521  https://github.com/jazzband/django-pipeline/is...   \n",
       "\n",
       "                                                 title  visit_count  \\\n",
       "188  scikit-learn/dbscan_.py at master · scikit-lea...            1   \n",
       "214  one kdeplot function error of seaborn · Issue ...            2   \n",
       "215  one kdeplot function error of seaborn · Issue ...            2   \n",
       "216  one kdeplot function error of seaborn · Issue ...            3   \n",
       "217  one kdeplot function error of seaborn · Issue ...            3   \n",
       "218  one kdeplot function error of seaborn · Issue ...            3   \n",
       "223  How to plot nice 2d density plots of samples i...            1   \n",
       "224  How to plot nice 2d density plots of samples i...            1   \n",
       "225  How to plot nice 2d density plots of samples i...            1   \n",
       "226  How to plot nice 2d density plots of samples i...            2   \n",
       "227  How to plot nice 2d density plots of samples i...            2   \n",
       "228  How to plot nice 2d density plots of samples i...            1   \n",
       "521  UnicodeDecodeError: 'utf-8' codec can't decode...            1   \n",
       "\n",
       "     typed_count       dt_last_visit        documents  \n",
       "188            0 2018-03-30 02:20:08       github.com  \n",
       "214            0 2018-03-30 01:23:18       github.com  \n",
       "215            0 2018-03-30 01:23:18       github.com  \n",
       "216            0 2018-03-30 01:23:17       github.com  \n",
       "217            0 2018-03-30 01:23:17       github.com  \n",
       "218            0 2018-03-30 01:23:17       github.com  \n",
       "223            0 2018-03-30 01:19:03  gist.github.com  \n",
       "224            0 2018-03-30 01:19:03       github.com  \n",
       "225            0 2018-03-30 01:19:03  gist.github.com  \n",
       "226            0 2018-03-30 01:19:03  gist.github.com  \n",
       "227            0 2018-03-30 01:19:03  gist.github.com  \n",
       "228            0 2018-03-30 01:19:03  gist.github.com  \n",
       "521            0 2018-03-28 02:03:22       github.com  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chrome_history.groupby(['documents'])[['id']].count().sort_values(['id'] , ascending = False)\n",
    "df_chrome_history[(df_chrome_history.dt_last_visit > pd.to_datetime('20180301', format='%Y%m%d', errors='ignore'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "punctuation_pattern = ' |\\.$|\\. |, |\\/|\\(|\\)|\\'|\\\"|\\!|\\?|\\+|\\:'\n",
    "documents = [re.split('/', x)[2] for x in  df_chrome_history['url']]\n",
    "text = [re.split(punctuation_pattern, x.lower()) for x in  df_chrome_history['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время, затраченное lemmatize- 16.607476 на обработку  \n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#стеммизируем слова\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "import pymystem3\n",
    "mystem = pymystem3 . Mystem ( )\n",
    "\n",
    "r = 0\n",
    "for row in text:\n",
    "    row_new = []\n",
    "    for word in row:\n",
    "        word = word.encode('utf8','ignore').decode()\n",
    "        if len(word) > 3 and '\\\\u' != word[:2] and '<' != word[:1] and '\\\\' != word[:1]:\n",
    "            \n",
    "            #test\n",
    "            if r <= 1:\n",
    "                new_word = mystem.lemmatize (word)[0]\n",
    "            else:\n",
    "                new_word = word\n",
    "            row_new.append(new_word)\n",
    "        \n",
    "    \n",
    "    text[r] = row_new\n",
    "    r += 1\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "stop = time.time()\n",
    "print (u\"Время, затраченное lemmatize- %f на обработку  \"%(stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bigartm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vowpalrabbit\n",
    "import codecs\n",
    "history_vowpalrabbit_all = ''\n",
    "\n",
    "text_file = codecs.open(\"chrome_history_vowpalrabbit.txt\", \"w\", \"utf-8\")\n",
    "errors = 0\n",
    "for doc, row in zip(documents,text):\n",
    "    row_str = ' '.join(row)\n",
    "    seq = (doc , '|' , 'text ' , row_str , ' \\n')\n",
    "    history_vowpalrabbit = ''.join(seq)\n",
    "    try:\n",
    "        text_file.write(history_vowpalrabbit)\n",
    "    except:\n",
    "        errors += 1\n",
    "        continue\n",
    "    \n",
    "    \n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import artm\n",
    "folder = 'chrome_history_bathces'\n",
    "data = \"chrome_history_vowpalrabbit.txt\"\n",
    "\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path=data, data_format=\"vowpal_wabbit\", target_folder=folder, \n",
    "                                       batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = artm.Dictionary(data_path=folder)# загрузка данных в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf8 -*-\n",
    "model = artm.ARTM(num_topics=3,\n",
    "                  num_document_passes=10,#10 проходов по документу\n",
    "                  dictionary=dictionary,\n",
    "                  scores=[artm.TopTokensScore(name='top_tokens_score')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)#10 проходов по коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_tokens = model.score_tracker['top_tokens_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0\n",
      "seaborn - 0.222\n",
      "mwaskom - 0.111\n",
      "error - 0.111\n",
      "kdeplot - 0.111\n",
      "issue - 0.111\n",
      "function - 0.111\n",
      "#1092 - 0.089\n",
      "scikit - 0.067\n",
      "# - 0.022\n",
      "master - 0.022\n",
      "topic_1\n",
      "byte - 0.143\n",
      "start - 0.071\n",
      "invalid - 0.071\n",
      "0xf6 - 0.071\n",
      "#651 - 0.071\n",
      "decode - 0.071\n",
      "codec - 0.071\n",
      "utf-8 - 0.071\n",
      "unicodedecodeerror - 0.071\n",
      "position - 0.071\n",
      "topic_2\n",
      "python - 0.167\n",
      "samples - 0.167\n",
      "plots - 0.167\n",
      "nice - 0.167\n",
      "plot - 0.167\n",
      "density - 0.167\n"
     ]
    }
   ],
   "source": [
    "for topic_name in model.topic_names:\n",
    "    print (topic_name)\n",
    "    for (token, weight) in zip(top_tokens.last_tokens[topic_name],\n",
    "                               top_tokens.last_weights[topic_name]):    \n",
    "         print (token, '-', round(weight,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seaborn'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#из топика найдем новость в интернете\n",
    "top_tokens.last_tokens['topic_0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#новостной сайт - https://newsapi.org/docs/client-libraries/python - ищет только в цензорных\n",
    "#новострной сайт 2 - https://webhose.io/web-content-api - крутой везде ище\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "#from newsapi import NewsApiClient\n",
    "\n",
    "newsapi_key = 'f45b069a9ab844369005986b34bb6764'\n",
    "webhose_key = '96b16ce1-f430-45fb-937f-14c395579994'\n",
    "text = 'http://webhose.io/filterWebContent?token='+webhose_key+'&format=json&ts=1520713935519&sort=crawled&q=sportage%20language%3Arussian%20site%3Adrom.ru'\n",
    "r = requests.get(text, auth=('user', 'pass'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_response = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moreResultsAvailable': 0,\n",
       " 'next': '/filterWebContent?token=96b16ce1-f430-45fb-937f-14c395579994&format=json&ts=1521672610018&q=sportage+language%3Arussian+site%3Adrom.ru&sort=crawled',\n",
       " 'posts': [{'author': '',\n",
       "   'crawled': '2018-03-22T00:50:10.018+02:00',\n",
       "   'entities': {'locations': [], 'organizations': [], 'persons': []},\n",
       "   'external_links': [],\n",
       "   'highlightText': '',\n",
       "   'highlightTitle': '',\n",
       "   'language': 'russian',\n",
       "   'ord_in_thread': 0,\n",
       "   'published': '2018-03-21T17:22:00.000+02:00',\n",
       "   'rating': None,\n",
       "   'text': 'Не пройдет любой автомобиль). Вы все врете). Только корейцы и японцы. После того, как даже в России люди стали понимать, что цены на Хайлендер и Прадо- совсем не равны их оснащаемости и качеству- продажи падают который месяц подряд. Но, что делать, надо же ваньке русскому впаривать Субару за 2500, который стоит 1млн 500. И мы достаем из кармана надежность, и Тойота за 5 американских зарплат, становится надежным бизнес автомобилем Камри, а не сел=поехал у лати Смотрим на 2 литра у Оптимы, Санты, Спорта и так далее- миллионные отзывы в США. Самые ненадежные двигатели. В России- нет, все знают, что атмосферники от азиатов надежны). Вас разводят, как лохов сказками про 5 лет гарантии и вы снимаете лапшу с ушей. \"Автомобилестроительные корпорации Hyundai Motor и Kia Motors отзывают из-за дефекта в двигателе 1,4 млн машин в США, Канаде и Южной Корее, сообщает AP. По данным Reuters речь идет об отзыве почти 1,5 млн автомобилей, но только в США и Южней Корее. При этом в США речь идет об отзыве примерно 1,3 млн автомобилей. Отзыв автомобилей начнется 19 мая и распространится на наиболее популярные в США модели - внедорожник Hyundai Santa Fe и Sonata, а также Kia Optima 2011-2014 годов выпуска и внедорожники Kia Sportage 2011-2013 годов и Kia Sorento 2012-2014 годов. За последние два года в США это уже второй случай отзыва большой партии машин из-за возможных проблем с двигателем. В сентябре 2015 года Hyundai Motor отозвала 470 тыс. машин модели Sonata выпуска 2011-2012 годов. \" В ТЛК лучше Айсин чем Айсин в Туареге? Торсен в ТЛК лучше? А может пневма? Лучше свечи, аккумуляторы? Нет, может дольше рулевая не беспокоит, реже надо менять тормозные колодки, лучше стекла? Бензонасос? Может в ТЛК лучше климатика или навигация? Или качество металла? А может ТЛК просто имеет лучшее сердце? Дизель надежен?))) А может бензиновый двигатель экономичен и надежен?). Расскажите про то, как надежен вариатор на Короле, или супер связка 3, 5 двиг+ акпп на Камри? А может турбины японские надежней? Вы живете байками. В 90= х годами авто были проще. До сих пор гоняют десятки тысяч старых Корол и Камри. старых Гольфоф и Пассатов. Главные хиты:бизнес класс Соната у китайцев и Камри у японцев. Надежно, солидно:))). Секта, глупая и затюканная. По России по путешествуйте. Проезжаешь одну деревню- здесь родился конструктор танка Т-34. Другую деревню- космонавт или авиамодельер. А сейчас? Во что вы превратились, бабы?). Ваш уровень Солярис и оклад в 200 долларов и разговоры про надежность чего то там. Авто- состоит из агрегатов и узлов! Надежность может быть конкретно чего то, а не абстрактно! 16',\n",
       "   'thread': {'country': 'RU',\n",
       "    'domain_rank': 752,\n",
       "    'main_image': 'https://s.auto.drom.ru/i24219/pubs/4/59535/gen340_2798380.jpg',\n",
       "    'participants_count': 0,\n",
       "    'performance_score': 0,\n",
       "    'published': '2018-03-21T17:22:00.000+02:00',\n",
       "    'replies_count': 0,\n",
       "    'section_title': 'Drom.ru: Новости',\n",
       "    'site': 'drom.ru',\n",
       "    'site_categories': ['car_culture', 'vehicles', 'auto_parts'],\n",
       "    'site_full': 'news.drom.ru',\n",
       "    'site_section': 'http://www.drom.ru/export/xml/news.rss',\n",
       "    'site_type': 'news',\n",
       "    'social': {'facebook': {'comments': 0, 'likes': 18, 'shares': 18},\n",
       "     'gplus': {'shares': 0},\n",
       "     'linkedin': {'shares': 0},\n",
       "     'pinterest': {'shares': 0},\n",
       "     'stumbledupon': {'shares': 0},\n",
       "     'vk': {'shares': 0}},\n",
       "    'spam_score': 0.0,\n",
       "    'title': 'В США выбрали машины, которых точно хватит на 300 тысяч км пробега',\n",
       "    'title_full': 'В США выбрали машины, которых точно хватит на 300 тысяч км пробега',\n",
       "    'url': 'http://omgili.com/ri/.wHSUbtEfZS0c0q2sYVQ5T1kBRYqPfavE0A0OiCkwCs-',\n",
       "    'uuid': '54981c13cb960ec10d61f8a31f47937c5ee9bcfe'},\n",
       "   'title': 'В США выбрали машины, которых точно хватит на 300 тысяч км пробега',\n",
       "   'url': 'http://omgili.com/ri/.wHSUbtEfZS0c0q2sYVQ5T1kBRYqPfavE0A0OiCkwCs-',\n",
       "   'uuid': '54981c13cb960ec10d61f8a31f47937c5ee9bcfe'}],\n",
       " 'requestsLeft': 981,\n",
       " 'totalResults': 1}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\bs4\\element.py:15: DeprecationWarning: invalid escape sequence \\s\n",
      "  whitespace_re = re.compile(\"\\s+\")\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\bs4\\element.py:1407: DeprecationWarning: invalid escape sequence \\d\n",
      "  pseudo_attributes = re.match('([a-zA-Z\\d-]+)\\(([a-zA-Z\\d]+)\\)', pseudo)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\bs4\\dammit.py:49: DeprecationWarning: invalid escape sequence \\?\n",
      "  '^<\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\?>'.encode(), re.I)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\lxml\\_elementpath.py:63: DeprecationWarning: invalid escape sequence \\.\n",
      "  \"\\.\\.|\"\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\lxml\\_elementpath.py:64: DeprecationWarning: invalid escape sequence \\(\n",
      "  \"\\(\\)|\"\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\lxml\\_elementpath.py:65: DeprecationWarning: invalid escape sequence \\[\n",
      "  \"[/.*:\\[\\]\\(\\)@=])|\"\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\lxml\\_elementpath.py:66: DeprecationWarning: invalid escape sequence \\{\n",
      "  \"((?:\\{[^}]+\\})?[^/\\[\\]\\(\\)@=\\s]+)|\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
